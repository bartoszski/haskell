{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4819c9fa",
   "metadata": {},
   "source": [
    ":!cabal install --lib pptable\n",
    ":!cabal install --lib vector\n",
    ":!cabal install --lib pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0662e8ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    ":load ParseLoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042206fc",
   "metadata": {},
   "source": [
    "### create Location for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c133f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Location {database = \"ushvr12\", dbdesc = \"dev\", host = \"odp-us-innovation-postgres-db.cxzrm3enxxmy.us-east-1.rds.amazonaws.com\", loc_name = \"sedhp\", loc_class = \"oracle\", loc_directory = \"/u01/app/oracle/product/19.3.0.0/dbee_1\", loc_remote_node = \"ora-mke2-scanp.am.health.ge.com\", loc_remote_login = \"gehc_hvr5\", loc_remote_pwd = \"\", loc_remote_port = 4344, loc_db_name = \"\", loc_db_user = \"PLANT_USER_ODP/!{r/2axxMra/8grrk/}!@ora-mke2-scanp.am.health.ge.com:1521/prd1mes\", loc_description = \"scdhp connection\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06a2d1",
   "metadata": {},
   "source": [
    "####  Visualize Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a2d6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location {\n",
       "  database = ushvr12\n",
       "  dbdesc = dev\n",
       "  host = odp-us-innovation-postgres-db.cxzrm3enxxmy.us-east-1.rds.amazonaws.com\n",
       "  loc_name = sedhp\n",
       "  loc_class = oracle\n",
       "  loc_directory = /u01/app/oracle/product/19.3.0.0/dbee_1\n",
       "  loc_remote_node = ora-mke2-scanp.am.health.ge.com\n",
       "  loc_remote_login = gehc_hvr5\n",
       "  loc_remote_pwd = \n",
       "  loc_remote_port = 4344\n",
       "  loc_db_name = \n",
       "  loc_db_user = PLANT_USER_ODP/!{r/2axxMra/8grrk/}!@ora-mke2-scanp.am.health.ge.com:1521/prd1mes\n",
       "  loc_description = scdhp connection\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Data.Text.Prettyprint.Doc\n",
    "\n",
    "pretty x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a14c6b",
   "metadata": {},
   "source": [
    "### load Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa426c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2596"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Data.Aeson\n",
    "import qualified Data.ByteString.Lazy as B\n",
    "import Control.Applicative\n",
    "\n",
    "input <- B.readFile \"data2.json\"\n",
    "let mm = decode input :: Maybe [Location]\n",
    "(length.unjust) mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c58e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = unjust mm\n",
    "let l_example =  (l!!2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7c44c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location {\n",
       "  database = ushvr12\n",
       "  dbdesc = dev\n",
       "  host = odp-us-innovation-postgres-db.cxzrm3enxxmy.us-east-1.rds.amazonaws.com\n",
       "  loc_name = sedhp\n",
       "  loc_class = oracle\n",
       "  loc_directory = /u01/app/oracle/product/19.3.0.0/dbee_1\n",
       "  loc_remote_node = ora-mke2-scanp.am.health.ge.com\n",
       "  loc_remote_login = gehc_hvr5\n",
       "  loc_remote_pwd = \n",
       "  loc_remote_port = 4344\n",
       "  loc_db_name = \n",
       "  loc_db_user = PLANT_USER_ODP/!{r/2axxMra/8grrk/}!@ora-mke2-scanp.am.health.ge.com:1521/prd1mes\n",
       "  loc_description = scdhp connection\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty l_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3c056",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63c336",
   "metadata": {},
   "source": [
    "import qualified Data.Text as T (Text,append,pack,unpack,head,take,splitOn,intercalate)\n",
    "import Data.Maybe (fromMaybe)\n",
    "import qualified Data.ByteString.Lazy.Char8 as BSL\n",
    "import qualified Data.Vector as V\n",
    "\n",
    "--- Redshift parser\n",
    "\n",
    "parseRedshift :: Location  -> [T.Text]\n",
    "parseRedshift l  = getUSer l : (map T.pack . concat . filterCols . fromMaybe []. parseJson .  getJsonStr)  l  \n",
    "   where\n",
    "       getJsonStr  = BSL.pack. T.unpack .last . T.splitOn \"=\" . loc_db_name  -- get loc_db_name and return string after first '='\n",
    "       parseJson s = decode s :: Maybe [[String]]            -- parse to list\n",
    "       filterCols  = map tail .  filter (\\[k, _] -> k `elem` [\"db_node\", \"db_name\"])\n",
    "       getUSer     = head . T.splitOn \"/\" . loc_db_user\n",
    "--- Kafka parser\n",
    "\n",
    "getKafkaString   = BSL.pack .T.unpack . last . T.splitOn \"=\" \n",
    "\n",
    "valueFromString :: BSL.ByteString -> Maybe Value\n",
    "valueFromString  s = decode  s :: Maybe Value\n",
    "\n",
    "unjust :: Maybe a -> a\n",
    "unjust (Just a) = a\n",
    "\n",
    "unArray :: Value -> [Value]\n",
    "unArray (Array x )  = V.toList x\n",
    "\n",
    "valueToText :: Value ->  T.Text\n",
    "valueToText val = case toJSON val of\n",
    "     String txt ->  txt\n",
    "\n",
    "listFromArray    = T.intercalate \";\" . map valueToText . unArray\n",
    "\n",
    "unString :: [Value] -> [T.Text]\n",
    "unString  [String x , String y] = [x,  y]\n",
    "unString  [String x , Array y]  = [x , listFromArray (Array y) ]\n",
    "\n",
    "getval :: T.Text -> [[T.Text]] -> T.Text\n",
    "getval key records =\n",
    "    case filter (\\[k, _] -> k == key) records of\n",
    "        [] -> \"\"  -- Return an empty string when no match is found\n",
    "        [[_, value]] -> value\n",
    "        _ -> error \"Multiple matches found\"  -- Handle this case as needed\n",
    "\n",
    "getvals :: [T.Text] -> [[T.Text]] -> [T.Text]\n",
    "getvals keys lst  = map (`getval` lst) keys\n",
    "\n",
    "parseKafkaString =    map (unString . unArray) . unArray . unjust .  valueFromString\n",
    "\n",
    "--- PARSER \n",
    "\n",
    "parseLoc :: Location  -> Location'\n",
    "parseLoc l \n",
    "    | loc_class l == \"file\" && ((T.head . loc_directory)   l  == '/' )     = file_locdir l\n",
    "    | loc_class l == \"file\" && ((T.take 4 . loc_directory) l  == \"s3s:\" )  = file_s3s l\n",
    "    | loc_class l == \"file\" && ((T.take 5 . loc_directory) l  == \"sftp:\")  = file_sftp l\n",
    "    | loc_class l `elem` [\"mysql\",\"greenplum\",\"postgresql\"]                = mysql l \n",
    "    | loc_class l == \"sqlserver\"                                           = sqlserver l\n",
    "    | loc_class l == \"teradata\"                                            = teradata l \n",
    "    | loc_class l == \"salesforce\"                                          = salesforce l \n",
    "    | loc_class l == \"redshift\"                                            = redsfhit l  \n",
    "    | loc_class l == \"kafka\"                                               = kafka l  \n",
    "    | otherwise   = loc2Location l \"\"  [\"###\",\"###\",\"###\"]                                           \n",
    "     where\n",
    "        file_locdir x = loc2Location x  \"_locdir\"  [loc_remote_login  x ,loc_remote_node x, loc_directory x]\n",
    "        --\n",
    "        getBacket  =  head . T.splitOn \"/\"  . last. T.splitOn \"@\" .loc_directory\n",
    "        getPrefix  =  T.intercalate  \"/\" .tail . T.splitOn \"/\" . last. T.splitOn \"@\" .loc_directory\n",
    "        file_s3s x =  loc2Location x \"_s3s\" [\"###\",getBacket x ,getPrefix x]\n",
    "        --\n",
    "        getsftpNode   = getBacket\n",
    "        getsftpFolder =  getPrefix\n",
    "        file_sftp x   = loc2Location x \"_sftp\" [\"###\",getsftpNode x ,getsftpFolder x]\n",
    "        --\n",
    "        getNodeMysql  =  head . T.splitOn \"~\" . loc_db_name\n",
    "        getInstMysql  =  last . T.splitOn \"~\" . loc_db_name\n",
    "        getUserMysql  =  head . T.splitOn \"/\" . loc_db_user\n",
    "        mysql x =  loc2Location x \"\"   [ getUserMysql x , getNodeMysql x, getInstMysql x]\n",
    "        --\n",
    "        getNodeMsSql  =  head . T.splitOn \"\\\\\" . loc_db_name\n",
    "        getInstMsSql  =  last . T.splitOn \"\\\\\" . loc_db_name\n",
    "        getUserMsSql  =  getUserMysql\n",
    "        sqlserver x   = loc2Location x \"\"   [getUserMsSql x, getNodeMsSql x,getInstMsSql x]\n",
    "        --\n",
    "        getUserTd     =  getUserMysql\n",
    "        teradata x = loc2Location x \"\"   [getUserTd x, loc_db_name x,getUserTd x]\n",
    "        --\n",
    "        getNodeSf     = last .T.splitOn \"//\" . loc_directory\n",
    "        getInstSf     = last .T.splitOn \"@\" . head . T.splitOn \"/\" . loc_db_user\n",
    "        getUserSf     = head .T.splitOn \"@\" . head . T.splitOn \"/\" . loc_db_user\n",
    "        salesforce x  = loc2Location x \"\"   [getUserSf x, getNodeSf x,getInstSf x]\n",
    "        --\n",
    "        redsfhit x    = loc2Location x \"\"  (parseRedshift x)\n",
    "        --\n",
    "        parseKafka =  getvals [\"ssl_key\",\"urls\",\"dummy\"] . parseKafkaString . getKafkaString .loc_db_name\n",
    "        kafka x    =  loc2Location x \"\"  (parseKafka x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca4051",
   "metadata": {},
   "source": [
    "import qualified Data.Text as T (Text,append,pack,unpack,head,take,splitOn,intercalate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb853c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Styles used for the Hoogle display in the pager */\n",
       ".hoogle-doc {\n",
       "display: block;\n",
       "padding-bottom: 1.3em;\n",
       "padding-left: 0.4em;\n",
       "}\n",
       ".hoogle-code {\n",
       "display: block;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "}\n",
       ".hoogle-text {\n",
       "display: block;\n",
       "}\n",
       ".hoogle-name {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-head {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-sub {\n",
       "display: block;\n",
       "margin-left: 0.4em;\n",
       "}\n",
       ".hoogle-package {\n",
       "font-weight: bold;\n",
       "font-style: italic;\n",
       "}\n",
       ".hoogle-module {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-class {\n",
       "font-weight: bold;\n",
       "}\n",
       "\n",
       ".get-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "white-space: pre-wrap;\n",
       "}\n",
       ".show-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "margin-left: 1em;\n",
       "}\n",
       ".mono {\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "}\n",
       ".err-msg {\n",
       "color: red;\n",
       "font-style: italic;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "display: block;\n",
       "}\n",
       "#unshowable {\n",
       "color: red;\n",
       "font-weight: bold;\n",
       "}\n",
       ".err-msg.in.collapse {\n",
       "padding-top: 0.7em;\n",
       "}\n",
       "\n",
       ".highlight-code {\n",
       "white-space: pre;\n",
       "font-family: monospace;\n",
       "}\n",
       "\n",
       ".suggestion-warning { \n",
       "font-weight: bold;\n",
       "color: rgb(200, 130, 0);\n",
       "}\n",
       ".suggestion-error { \n",
       "font-weight: bold;\n",
       "color: red;\n",
       "}\n",
       ".suggestion-name {\n",
       "font-weight: bold;\n",
       "}\n",
       "\n",
       "</style><div class=\"suggestion-name\" style=\"clear:both;\">Use ==</div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Found:</div><div class=\"highlight-code\" id=\"haskell\">loc_class l `elem` [\"kafka\"]</div></div><div class=\"suggestion-row\" style=\"float: left;\"><div class=\"suggestion-warning\">Why Not:</div><div class=\"highlight-code\" id=\"haskell\">loc_class l == \"kafka\"</div></div>"
      ],
      "text/plain": [
       "Line 3: Use ==\n",
       "Found:\n",
       "loc_class l `elem` [\"kafka\"]\n",
       "Why not:\n",
       "loc_class l == \"kafka\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qualified Data.Text as T ( take )\n",
    "ff l = loc_class l == \"file\" && ((T.take 5 . loc_directory) l  == \"sftp:\")  \n",
    "f l  = loc_class l `elem` [\"kafka\"]\n",
    "ll   = filter  f   l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b180206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Location {\n",
       "  database = ushvr04\n",
       "  dbdesc = US hvr prod\n",
       "  host = odp-us-prod-hvr-metadata-db.cjyhx859wwhg.us-east-1.rds.amazonaws.com\n",
       "  loc_name = kafpr\n",
       "  loc_class = kafka\n",
       "  loc_directory = \n",
       "  loc_remote_node = 10.242.109.196\n",
       "  loc_remote_login = hvr\n",
       "  loc_remote_pwd = !{.wruWtPV}!\n",
       "  loc_remote_port = 4343\n",
       "  loc_db_name = JSON=[[\"urls\",[\"b-1.odp-us-prod-daas-msk.2mp3k5.c7.kafka.us-east-1.amazonaws.com:9094\",\"b-3.odp-us-prod-daas-msk.2mp3k5.c7.kafka.us-east-1.amazonaws.com:9094\",\"b-2.odp-us-prod-daas-msk.2mp3k5.c7.kafka.us-east-1.amazonaws.com:9094\"]],[\"broker_ca\",\"/data/kafka_prod/MSKPOCKey.pem\"],[\"ssl_cert\",\"/data/kafka_prod/kafka_prod/signed-certificate-from-acm\"],[\"ssl_key\",\"/data/kafka_prod/kafka_prod/key.pem\"],[\"ssl_key_pwd\",\"!{KQzkyRXnkSraWtnX}!\"]]\n",
       "  loc_db_user = \n",
       "  loc_description = kafka prod\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length ll\n",
    "k = head  ll\n",
    "pretty k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b475fb",
   "metadata": {},
   "source": [
    "import qualified Data.ByteString.Lazy.Char8 as BSL\n",
    "import qualified Data.Vector as V\n",
    "import qualified Data.Text as T (Text,append,pack,unpack,head,take,splitOn,intercalate)\n",
    "\n",
    "getKafkaString   = BSL.pack .T.unpack . last . T.splitOn \"=\" \n",
    "\n",
    "valueFromString :: LBS.ByteString -> Maybe Value\n",
    "valueFromString  s = decode  s :: Maybe Value\n",
    "\n",
    "unjust :: Maybe a -> a\n",
    "unjust (Just a) = a\n",
    "\n",
    "unArray :: Value -> [Value]\n",
    "unArray (Array x )  = V.toList x\n",
    "\n",
    "valueToText :: Value ->  T.Text\n",
    "valueToText val = case toJSON val of\n",
    "     String txt ->  txt\n",
    "\n",
    "listFromArray    = T.intercalate \";\" . map valueToText . unArray\n",
    "\n",
    "unString :: [Value] -> [T.Text]\n",
    "unString  [String x , String y] = [x,  y]\n",
    "unString  [String x , Array y]  = [x , listFromArray (Array y) ]\n",
    "\n",
    "getval :: T.Text -> [[T.Text]] -> T.Text\n",
    "getval key records =\n",
    "    case filter (\\[k, _] -> k == key) records of\n",
    "        [] -> \"\"  -- Return an empty string when no match is found\n",
    "        [[_, value]] -> value\n",
    "        _ -> error \"Multiple matches found\"  -- Handle this case as needed\n",
    "\n",
    "getvals :: [T.Text] -> [[T.Text]] -> [T.Text]\n",
    "getvals keys lst  = map (`getval` lst) keys\n",
    "\n",
    "parseKafkaString =    map (unString . unArray) . unArray . unjust .  valueFromString\n",
    "\n",
    "\n",
    "parseKafka =  getvals [\"ssl_key\",\"urls\",\"dummy\"] . parseKafkaString . getKafkaString .loc_db_name\n",
    "parseKafka  k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d705f87f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Location {\n",
       "  database         = ushvr04\n",
       "  dbdesc           = US hvr prod\n",
       "  host             = odp-us-prod-hvr-metadata-db.cjyhx859wwhg.us-east-1.rds.amazonaws.com\n",
       "  loc_class        = kafka\n",
       "   loc_name         = kafpr\n",
       "   loc_directory    = \n",
       "   loc_remote_node  = 10.242.109.196\n",
       "   loc_remote_login = hvr\n",
       "   loc_remote_port  = 4343\n",
       "   loc_db_user      = /data/kafka_prod/kafka_prod/key.pem\n",
       "   loc_description  = kafka prod\n",
       "   db_node_name     = b-1.odp-us-prod-daas-msk.2mp3k5.c7.kafka.us-east-1.amazonaws.com:9094;b-3.odp-us-prod-daas-msk.2mp3k5.c7.kafka.us-east-1.amazonaws.com:9094;b-2.odp-us-prod-daas-msk.2mp3k5.c7.kafka.us-east-1.amazonaws.com:9094\n",
       "   db_instance      = \n",
       "},Location {\n",
       "  database         = ushvr04\n",
       "  dbdesc           = US hvr prod\n",
       "  host             = odp-us-prod-hvr-metadata-db.cjyhx859wwhg.us-east-1.rds.amazonaws.com\n",
       "  loc_class        = kafka\n",
       "   loc_name         = kafk\n",
       "   loc_directory    = \n",
       "   loc_remote_node  = 10.242.112.153\n",
       "   loc_remote_login = hvr2\n",
       "   loc_remote_port  = 9090\n",
       "   loc_db_user      = /home/hvr2/hvr_home/lib/cert/key.pem\n",
       "   loc_description  = New kafka with SSL enables\n",
       "   db_node_name     = b-1.us-dev-msk-cluster.x8853p.c1.kafka.us-east-1.amazonaws.com:9094;b-2.us-dev-msk-cluster.x8853p.c1.kafka.us-east-1.amazonaws.com:9094;b-3.us-dev-msk-cluster.x8853p.c1.kafka.us-east-1.amazonaws.com:9094\n",
       "   db_instance      = \n",
       "},Location {\n",
       "  database         = ushvr04\n",
       "  dbdesc           = US hvr prod\n",
       "  host             = odp-us-prod-hvr-metadata-db.cjyhx859wwhg.us-east-1.rds.amazonaws.com\n",
       "  loc_class        = kafka\n",
       "   loc_name         = kafka\n",
       "   loc_directory    = \n",
       "   loc_remote_node  = 10.242.109.196\n",
       "   loc_remote_login = hvr\n",
       "   loc_remote_port  = 4343\n",
       "   loc_db_user      = /data/kafka_devcerts/kafka/key.pem\n",
       "   loc_description  = New kafka with SSL enables\n",
       "   db_node_name     = b-1.us-dev-msk-cluster.x8853p.c1.kafka.us-east-1.amazonaws.com:9094;b-2.us-dev-msk-cluster.x8853p.c1.kafka.us-east-1.amazonaws.com:9094;b-3.us-dev-msk-cluster.x8853p.c1.kafka.us-east-1.amazonaws.com:9094\n",
       "   db_instance      = \n",
       "},Location {\n",
       "  database         = ushvr04\n",
       "  dbdesc           = US hvr prod\n",
       "  host             = odp-us-prod-hvr-metadata-db.cjyhx859wwhg.us-east-1.rds.amazonaws.com\n",
       "  loc_class        = kafka\n",
       "   loc_name         = kafst\n",
       "   loc_directory    = \n",
       "   loc_remote_node  = 10.242.109.196\n",
       "   loc_remote_login = hvr\n",
       "   loc_remote_port  = 4343\n",
       "   loc_db_user      = /data/kafka_devcerts/kafka/key.pem\n",
       "   loc_description  = kafka stage\n",
       "   db_node_name     = b-1.odp-us-innovation-daas.kifwzy.c8.kafka.us-east-1.amazonaws.com:9094;b-2.odp-us-innovation-daas.kifwzy.c8.kafka.us-east-1.amazonaws.com:9094;b-3.odp-us-innovation-daas.kifwzy.c8.kafka.us-east-1.amazonaws.com:9094\n",
       "   db_instance      = \n",
       "},Location {\n",
       "  database         = ushvr04\n",
       "  dbdesc           = US hvr prod\n",
       "  host             = odp-us-prod-hvr-metadata-db.cjyhx859wwhg.us-east-1.rds.amazonaws.com\n",
       "  loc_class        = kafka\n",
       "   loc_name         = kafp\n",
       "   loc_directory    = \n",
       "   loc_remote_node  = 10.242.109.196\n",
       "   loc_remote_login = hvr\n",
       "   loc_remote_port  = 4343\n",
       "   loc_db_user      = /data/kafka_prod/kafka_prod/key.pem\n",
       "   loc_description  = kafka daas prod\n",
       "   db_node_name     = b-1.odpusprodcdxnrtdaasms.0qj8eq.c13.kafka.us-east-1.amazonaws.com:9094;b-2.odpusprodcdxnrtdaasms.0qj8eq.c13.kafka.us-east-1.amazonaws.com:9094;b-3.odpusprodcdxnrtdaasms.0qj8eq.c13.kafka.us-east-1.amazonaws.com:9094\n",
       "   db_instance      = \n",
       "}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(map (pretty.parseLoc) . take 5 ) ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b03361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"redshift\",\"file\",\"oracle\",\"sqlserver\",\"teradata\",\"postgresql\",\"salesforce\",\"mysql\",\"greenplum\",\"kafka\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Data.List (nub)\n",
    "(nub. map loc_class) l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "9.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
